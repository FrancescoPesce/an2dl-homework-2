{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuwVgG3Vbbka"
   },
   "source": [
    "# Artificial Neural Networks and Deep Learning - Homework 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw_-hFm6bjY6"
   },
   "source": [
    "## 🌐 Connect Colab to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18713,
     "status": "ok",
     "timestamp": 1733131483014,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "y2S4GWr3Uoa8",
    "outputId": "042d4e46-a7fe-4a0f-f228-1950a9b08c7c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/gdrive\")\n",
    "# %cd /gdrive/My Drive/[2024-2025] AN2DL/Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## ⚙️ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7389,
     "status": "ok",
     "timestamp": 1733131490397,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "CO6_Ft_8T56A",
    "outputId": "55619170-643c-4414-e287-a01c5dbb8fed"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {tfk.__version__}\")\n",
    "print(f\"GPU devices: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## ⏳ Load and prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4437,
     "status": "ok",
     "timestamp": 1733131494829,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "pLaoDaG1V1Yg",
    "outputId": "0c213eab-3925-4a80-d5ce-79f5b8ca1e68"
   },
   "outputs": [],
   "source": [
    "data = np.load(\"mars_for_students.npz\")\n",
    "\n",
    "training_set = data[\"training_set\"]\n",
    "X_train = training_set[:, 0]\n",
    "y_train = training_set[:, 1]\n",
    "\n",
    "X_test = data[\"test_set\"]\n",
    "\n",
    "print(f\"Training X shape: {X_train.shape}\")\n",
    "print(f\"Training y shape: {y_train.shape}\")\n",
    "print(f\"Test X shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1733131495782,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "VmnTgJi_OOs1",
    "outputId": "6f4f416f-df91-4f36-963c-ced39baa9087"
   },
   "outputs": [],
   "source": [
    "# Add color channel and rescale pixels between 0 and 1\n",
    "X_train = X_train[..., np.newaxis] / 255.0\n",
    "X_test = X_test[..., np.newaxis] / 255.0\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1733131495782,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "i-n9_2Eftvp5"
   },
   "outputs": [],
   "source": [
    "# Split into training and validation (80-20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, random_state=seed, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1733131495782,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "bScns-4GYaOt"
   },
   "outputs": [],
   "source": [
    "category_map = {\n",
    "    0: 0,  # background\n",
    "    1: 1,  # soil\n",
    "    2: 2,  # bedrock\n",
    "    3: 3,  # sand\n",
    "    4: 4,  # big rock\n",
    "}\n",
    "\n",
    "\n",
    "def apply_category_mapping(label):\n",
    "    \"\"\"\n",
    "    Apply category mapping to labels.\n",
    "    \"\"\"\n",
    "    keys_tensor = tf.constant(list(category_map.keys()), dtype=tf.int32)\n",
    "    vals_tensor = tf.constant(list(category_map.values()), dtype=tf.int32)\n",
    "    table = tf.lookup.StaticHashTable(\n",
    "        tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), default_value=0\n",
    "    )\n",
    "    return table.lookup(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733131495782,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "rTVu93r6Yb8r"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def random_flip(image, label, seed=None):\n",
    "    \"\"\"Consistent random horizontal flip.\"\"\"\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(0, 1000000)\n",
    "    flip_prob = tf.random.uniform([], seed=seed)\n",
    "    image = tf.cond(\n",
    "        flip_prob > 0.5, lambda: tf.image.flip_left_right(image), lambda: image\n",
    "    )\n",
    "    label = tf.cond(\n",
    "        flip_prob > 0.5, lambda: tf.image.flip_left_right(label), lambda: label\n",
    "    )\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733131495783,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "-kKiHcV0YePz"
   },
   "outputs": [],
   "source": [
    "def make_dataset(images, labels, batch_size, shuffle=True, augment=False, seed=None):\n",
    "    \"\"\"\n",
    "    Create a memory-efficient TensorFlow dataset.\n",
    "    \"\"\"\n",
    "    # Add an axis to labels\n",
    "    new_labels = labels[..., np.newaxis]\n",
    "\n",
    "    # Create dataset from file paths\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, new_labels))\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=batch_size * 2, seed=seed)\n",
    "\n",
    "    # Apply category mapping\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: (x, apply_category_mapping(y)), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    if augment:\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: random_flip(x, y, seed=seed),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE,\n",
    "        )\n",
    "\n",
    "    # Batch the data\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1022,
     "status": "ok",
     "timestamp": 1733131496796,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "QWAcW_6IY2D0",
    "outputId": "cf57c7c5-f3d3-484f-e097-3f1422b83ece"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create the datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = make_dataset(\n",
    "    X_train,\n",
    "    y_train.astype(\"int32\"),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    augment=True,\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "val_dataset = make_dataset(\n",
    "    X_val, y_val.astype(\"int32\"), batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Datasets created!\")\n",
    "\n",
    "# Check the shape of the data\n",
    "for images, labels in train_dataset.take(1):\n",
    "    input_shape = images.shape[1:]\n",
    "    print(f\"\\nInput shape: {input_shape}\")\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(\"Labels dtype:\", labels.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-oP7zvmjmfx"
   },
   "source": [
    "## Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3764,
     "status": "ok",
     "timestamp": 1733131500555,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "J32MOnQaq_GA",
    "outputId": "ea132d36-8a20-45bf-edbe-7d0cc766dd06"
   },
   "outputs": [],
   "source": [
    "def create_segmentation_colormap(num_classes):\n",
    "    \"\"\"\n",
    "    Create a linear colormap using a predefined palette.\n",
    "    Uses 'viridis' as default because it is perceptually uniform\n",
    "    and works well for colorblindness.\n",
    "    \"\"\"\n",
    "    return plt.cm.viridis(np.linspace(0, 1, num_classes))\n",
    "\n",
    "\n",
    "def apply_colormap(label, colormap=None):\n",
    "    \"\"\"\n",
    "    Apply the colormap to a label.\n",
    "    \"\"\"\n",
    "    # Ensure label is 2D\n",
    "    label = np.squeeze(label)\n",
    "\n",
    "    if colormap is None:\n",
    "        num_classes = len(np.unique(label))\n",
    "        colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "    # Apply the colormap\n",
    "    colored = colormap[label.astype(int)]\n",
    "\n",
    "    return colored\n",
    "\n",
    "\n",
    "def plot_sample_batch(images, labels, num_samples=3):\n",
    "    \"\"\"\n",
    "    Display some image and label pairs from the dataset.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 4 * num_samples))\n",
    "\n",
    "    colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "    for j in range(min(num_samples, len(images))):\n",
    "        # Plot original image\n",
    "        plt.subplot(num_samples, 2, j * 2 + 1)\n",
    "        plt.imshow(images[j], cmap=\"grey\")\n",
    "        plt.title(f\"Image {j+1}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Plot colored label\n",
    "        plt.subplot(num_samples, 2, j * 2 + 2)\n",
    "        colored_label = apply_colormap(labels[j], colormap)\n",
    "        plt.imshow(colored_label)\n",
    "        plt.title(f\"Label {j+1}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Visualize examples from the training set\n",
    "print(\"Visualizing examples from the training set:\")\n",
    "plot_sample_batch(X_train, y_train, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1733131501247,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "xgIE-cdNLn4s",
    "outputId": "ffabe711-e5d0-491f-84b1-ac1a74d07f28"
   },
   "outputs": [],
   "source": [
    "# Visualize examples from the test set.\n",
    "num_samples = 4\n",
    "plt.figure(figsize=(15, 2 * num_samples))\n",
    "\n",
    "colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "for j in range(min(num_samples, len(X_test))):\n",
    "    plt.subplot(num_samples, 1, j + 1)\n",
    "    plt.imshow(X_test[j], cmap=\"grey\")\n",
    "    plt.title(f\"Image {j}\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSliIxBvbs2Q"
   },
   "source": [
    "## 🛠️ Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733131501248,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "uLNQR71Lsf7a"
   },
   "outputs": [],
   "source": [
    "def unet_block(\n",
    "    input_tensor, filters, kernel_size=3, activation=\"relu\", stack=2, name=\"\"\n",
    "):\n",
    "    # Initialise the input tensor\n",
    "    x = input_tensor\n",
    "\n",
    "    # Apply a sequence of Conv2D, Batch Normalisation, and Activation layers for the specified number of stacks\n",
    "    for i in range(stack):\n",
    "        x = tfkl.Conv2D(\n",
    "            filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            name=name + \"conv\" + str(i + 1),\n",
    "        )(x)\n",
    "        x = tfkl.BatchNormalization(name=name + \"bn\" + str(i + 1))(x)\n",
    "        x = tfkl.Activation(activation, name=name + \"activation\" + str(i + 1))(x)\n",
    "\n",
    "    # Return the transformed tensor\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1733131501248,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "NRNEskCXsiM_"
   },
   "outputs": [],
   "source": [
    "def get_unet_model(input_shape=(64, 128, 1), num_classes=num_classes, seed=seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    input_layer = tfkl.Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "    # Downsampling path\n",
    "    down_block_1 = unet_block(input_layer, 32, name=\"down_block1_\")\n",
    "    d1 = tfkl.MaxPooling2D()(down_block_1)\n",
    "\n",
    "    down_block_2 = unet_block(d1, 64, name=\"down_block2_\")\n",
    "    d2 = tfkl.MaxPooling2D()(down_block_2)\n",
    "\n",
    "    # Bottleneck\n",
    "    bottleneck = unet_block(d2, 128, name=\"bottleneck\")\n",
    "\n",
    "    # Upsampling path\n",
    "    u1 = tfkl.UpSampling2D()(bottleneck)\n",
    "    u1 = tfkl.Concatenate()([u1, down_block_2])\n",
    "    u1 = unet_block(u1, 64, name=\"up_block1_\")\n",
    "\n",
    "    u2 = tfkl.UpSampling2D()(u1)\n",
    "    u2 = tfkl.Concatenate()([u2, down_block_1])\n",
    "    u2 = unet_block(u2, 32, name=\"up_block2_\")\n",
    "\n",
    "    # Output Layer\n",
    "    output_layer = tfkl.Conv2D(\n",
    "        num_classes,\n",
    "        kernel_size=1,\n",
    "        padding=\"same\",\n",
    "        activation=\"softmax\",\n",
    "        name=\"output_layer\",\n",
    "    )(u2)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name=\"UNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1733131501248,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "VP8fEvC9vpsr"
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "epochs = 1000\n",
    "patience = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1733131501935,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "CBkb3TRF1KJx",
    "outputId": "d9cc7c54-b6c3-40d6-db3d-69785c5a83f1"
   },
   "outputs": [],
   "source": [
    "model = get_unet_model()\n",
    "\n",
    "# Print a detailed summary of the model with expanded nested layers and trainable parameters.\n",
    "model.summary(expand_nested=True, show_trainable=True)\n",
    "\n",
    "# Generate and display a graphical representation of the model architecture.\n",
    "tf.keras.utils.plot_model(model, show_trainable=True, expand_nested=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDBA-uBFsRAd"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733131501935,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "GyHMGG5EdXGr"
   },
   "outputs": [],
   "source": [
    "# Define custom Mean Intersection Over Union metric\n",
    "@tfk.utils.register_keras_serializable()\n",
    "class MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n",
    "    def __init__(\n",
    "        self, num_classes, labels_to_exclude=None, name=\"mean_iou\", dtype=None\n",
    "    ):\n",
    "        super(MeanIntersectionOverUnion, self).__init__(\n",
    "            num_classes=num_classes, name=name, dtype=dtype\n",
    "        )\n",
    "        if labels_to_exclude is None:\n",
    "            labels_to_exclude = [0]  # Default to excluding label 0\n",
    "        self.labels_to_exclude = labels_to_exclude\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert predictions to class labels\n",
    "        y_pred = tf.math.argmax(y_pred, axis=-1)\n",
    "\n",
    "        # Flatten the tensors\n",
    "        y_true = tf.reshape(y_true, [-1])\n",
    "        y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "        # Apply mask to exclude specified labels\n",
    "        for label in self.labels_to_exclude:\n",
    "            mask = tf.not_equal(y_true, label)\n",
    "            y_true = tf.boolean_mask(y_true, mask)\n",
    "            y_pred = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "        # Update the state\n",
    "        return super().update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "\n",
    "# Visualization callback\n",
    "class VizCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, image, label, frequency=5):\n",
    "        super().__init__()\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.frequency = frequency\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.frequency == 0:  # Visualize only every \"frequency\" epochs\n",
    "            image, label = self.image, self.label\n",
    "            label = apply_category_mapping(label)\n",
    "            pred = self.model.predict(image, verbose=0)\n",
    "            y_pred = tf.math.argmax(pred, axis=-1)\n",
    "            y_pred = y_pred.numpy()\n",
    "\n",
    "            # Create colormap\n",
    "            colormap = create_segmentation_colormap(num_classes)\n",
    "\n",
    "            plt.figure(figsize=(16, 4))\n",
    "\n",
    "            # Input image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image[0], cmap=\"grey\")\n",
    "            plt.title(\"Input Image\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Ground truth\n",
    "            plt.subplot(1, 3, 2)\n",
    "            colored_label = apply_colormap(label.numpy(), colormap)\n",
    "            plt.imshow(colored_label)\n",
    "            plt.title(\"Ground Truth Mask\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Prediction\n",
    "            plt.subplot(1, 3, 3)\n",
    "            colored_pred = apply_colormap(y_pred[0], colormap)\n",
    "            plt.imshow(colored_pred)\n",
    "            plt.title(\"Predicted Mask\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733131501936,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "BKIjlRxIdl6z",
    "outputId": "ca9362de-4739-4b63-b564-7be1e107e920"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "print(\"Compiling model...\")\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(num_classes=num_classes),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        MeanIntersectionOverUnion(num_classes=num_classes, labels_to_exclude=[0]),\n",
    "    ],\n",
    ")\n",
    "print(\"Model compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733131501936,
     "user": {
      "displayName": "Francesco Pesce",
      "userId": "06928891303402167220"
     },
     "user_tz": -60
    },
    "id": "J2f20uQ5tIMC"
   },
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mean_iou\", mode=\"max\", patience=patience, restore_best_weights=True\n",
    ")\n",
    "\n",
    "image, label = val_dataset.take(1).get_single_element()\n",
    "viz_callback = VizCallback(image[11:12, ...], label[11:12, ...])\n",
    "\n",
    "reduce_lr_callback = tfk.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", patience=patience / 2, factor=0.1, min_lr=learning_rate / 100\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, viz_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "pMCbSMQ_-XoH"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_meanIoU = round(max(history[\"val_mean_iou\"]) * 100, 2)\n",
    "print(f\"Final validation Mean Intersection Over Union: {final_val_meanIoU}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PtM0ubgdOzG-"
   },
   "outputs": [],
   "source": [
    "timestep_str = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "model_filename = f\"model_{timestep_str}.keras\"\n",
    "model.save(model_filename)\n",
    "del model\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNp6pUZuddqC"
   },
   "source": [
    "## 📊 Prepare Your Submission\n",
    "\n",
    "In our Kaggle competition, submissions are made as `csv` files. To create a proper `csv` file, you need to flatten your predictions and include an `id` column as the first column of your dataframe. To maintain consistency between your results and our solution, please avoid shuffling the test set. The code below demonstrates how to prepare the `csv` file from your model predictions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BU00iEFcYi_X"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# If model_filename is not defined, load the most recent model from Google Drive\n",
    "if \"model_filename\" not in globals() or model_filename is None:\n",
    "    files = [f for f in os.listdir('.') if os.path.isfile(f) and f.startswith('model_') and f.endswith('.keras')]\n",
    "    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "    if files:\n",
    "        model_filename = files[0]\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No model files found in the current directory.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FMIq69eWgRmr"
   },
   "outputs": [],
   "source": [
    "model = tfk.models.load_model(model_filename, compile=False)\n",
    "print(f\"Model loaded from {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "z287uIQ_VGoK"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "print(f\"Predictions shape: {preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SPjMEKqZW5jX"
   },
   "outputs": [],
   "source": [
    "def y_to_df(y) -> pd.DataFrame:\n",
    "    \"\"\"Converts segmentation predictions into a DataFrame format for Kaggle.\"\"\"\n",
    "    n_samples = len(y)\n",
    "    y_flat = y.reshape(n_samples, -1)\n",
    "    df = pd.DataFrame(y_flat)\n",
    "    df[\"id\"] = np.arange(n_samples)\n",
    "    cols = [\"id\"] + [col for col in df.columns if col != \"id\"]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "s18kX1uDconq"
   },
   "outputs": [],
   "source": [
    "# Create and download the csv submission file\n",
    "timestep_str = model_filename.replace(\"model_\", \"\").replace(\".keras\", \"\")\n",
    "submission_filename = f\"submission_{timestep_str}.csv\"\n",
    "submission_df = y_to_df(preds)\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download(submission_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQEgmFTPfz1n"
   },
   "source": [
    "#  \n",
    "<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/\n",
    "___\n",
    "Credits: Alberto Archetti 📧 alberto.archetti@polito.it\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "   Copyright 2024 Alberto Archetti\n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RNp6pUZuddqC"
   ],
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "an2dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
